{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic machine learning analysis\n",
    "\n",
    "#### Loading necessary modules for data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules for data analysis and data visualization. \n",
    "# Data analysis modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings                      ## importing warnings library. \n",
    "warnings.filterwarnings('ignore')    ## Ignore warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./datasets/titanic/train.csv\")\n",
    "test = pd.read_csv(\"./datasets/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Goldenberg, Mrs. Samuel L (Edwiga Grabowska)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17453</td>\n",
       "      <td>89.1042</td>\n",
       "      <td>C92</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>423</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Zimmerman, Mr. Leo</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315082</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Frost, Mr. Anthony Wood \"Archie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239854</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Frauenthal, Mrs. Henry William (Clara Heinshei...</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17611</td>\n",
       "      <td>133.6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Moussa, Mrs. (Mantoura Boulos)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2626</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "849          850         1       1   \n",
       "422          423         0       3   \n",
       "481          482         0       2   \n",
       "334          335         1       1   \n",
       "367          368         1       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "849       Goldenberg, Mrs. Samuel L (Edwiga Grabowska)  female   NaN      1   \n",
       "422                                 Zimmerman, Mr. Leo    male  29.0      0   \n",
       "481                   Frost, Mr. Anthony Wood \"Archie\"    male   NaN      0   \n",
       "334  Frauenthal, Mrs. Henry William (Clara Heinshei...  female   NaN      1   \n",
       "367                     Moussa, Mrs. (Mantoura Boulos)  female   NaN      0   \n",
       "\n",
       "     Parch    Ticket      Fare Cabin Embarked  \n",
       "849      0     17453   89.1042   C92        C  \n",
       "422      0    315082    7.8750   NaN        S  \n",
       "481      0    239854    0.0000   NaN        S  \n",
       "334      0  PC 17611  133.6500   NaN        S  \n",
       "367      0      2626    7.2292   NaN        C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Take a look at the overview of the dataset. \n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable Name | Description                       | Type    |\n",
    "|---------------|-----------------------------------|---------|\n",
    "| PassengerId   | Passenger's ID                    | int64   |\n",
    "| Survived      | Survived (1) or died (0)          | int64   |\n",
    "| Pclass        | Passenger’s class                 | int64   |\n",
    "| Name          | Passenger’s name                  | object  |\n",
    "| Sex           | Passenger’s sex                   | object  |\n",
    "| Age           | Passenger’s age                   | float64 |\n",
    "| SibSp         | Number of siblings/spouses aboard | int64   |\n",
    "| Parch         | Number of parents/children aboard | int64   |\n",
    "| Ticket        | Ticket number                     | object  |\n",
    "| Fare          | Fare                              | float64 |\n",
    "| Cabin         | Cabin                             | object  |\n",
    "| Embarked      | Port of embarkation               | object  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Notes\n",
    "\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1170</td>\n",
       "      <td>2</td>\n",
       "      <td>Ware, Mr. John James</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CA 31352</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1241</td>\n",
       "      <td>2</td>\n",
       "      <td>Walcroft, Miss. Nellie</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F.C.C. 13528</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1107</td>\n",
       "      <td>1</td>\n",
       "      <td>Head, Mr. Christopher</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113038</td>\n",
       "      <td>42.5</td>\n",
       "      <td>B11</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>944</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Miss. Ellen Nellie\"\"</td>\n",
       "      <td>female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>29105</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>1277</td>\n",
       "      <td>2</td>\n",
       "      <td>Herman, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>220845</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                           Name     Sex   Age  SibSp  \\\n",
       "278         1170       2           Ware, Mr. John James    male  30.0      1   \n",
       "349         1241       2         Walcroft, Miss. Nellie  female  31.0      0   \n",
       "215         1107       1          Head, Mr. Christopher    male  42.0      0   \n",
       "52           944       2  Hocking, Miss. Ellen Nellie\"\"  female  20.0      2   \n",
       "385         1277       2             Herman, Miss. Kate  female  24.0      1   \n",
       "\n",
       "     Parch        Ticket  Fare Cabin Embarked  \n",
       "278      0      CA 31352  21.0   NaN        S  \n",
       "349      0  F.C.C. 13528  21.0   NaN        S  \n",
       "215      0        113038  42.5   B11        S  \n",
       "52       1         29105  23.0   NaN        S  \n",
       "385      2        220845  65.0   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving passenger id in advance in order to submit later. \n",
    "passengerid = test.PassengerId\n",
    "\n",
    "## Replacing the null values in the Embarked column with the mode. \n",
    "train.Embarked.fillna(\"C\", inplace=True)\n",
    "\n",
    "## Concat train and test into a variable \"all_data\"\n",
    "survivers = train.Survived\n",
    "\n",
    "train.drop([\"Survived\"],axis=1, inplace=True)\n",
    "\n",
    "all_data = pd.concat([train,test], ignore_index=False)\n",
    "\n",
    "## Assign all the null values to N\n",
    "all_data.Cabin.fillna(\"N\", inplace=True)\n",
    "\n",
    "all_data.Cabin = [i[0] for i in all_data.Cabin]\n",
    "\n",
    "with_N = all_data[all_data.Cabin == \"N\"]\n",
    "\n",
    "without_N = all_data[all_data.Cabin != \"N\"]\n",
    "\n",
    "all_data.groupby(\"Cabin\")['Fare'].mean().sort_values()\n",
    "\n",
    "def cabin_estimator(i):\n",
    "    a = 0\n",
    "    if i<16:\n",
    "        a = \"G\"\n",
    "    elif i>=16 and i<27:\n",
    "        a = \"F\"\n",
    "    elif i>=27 and i<38:\n",
    "        a = \"T\"\n",
    "    elif i>=38 and i<47:\n",
    "        a = \"A\"\n",
    "    elif i>= 47 and i<53:\n",
    "        a = \"E\"\n",
    "    elif i>= 53 and i<54:\n",
    "        a = \"D\"\n",
    "    elif i>=54 and i<116:\n",
    "        a = 'C'\n",
    "    else:\n",
    "        a = \"B\"\n",
    "    return a\n",
    "    \n",
    "\n",
    "##applying cabin estimator function. \n",
    "with_N['Cabin'] = with_N.Fare.apply(lambda x: cabin_estimator(x))\n",
    "\n",
    "## getting back train. \n",
    "all_data = pd.concat([with_N, without_N], axis=0)\n",
    "\n",
    "## PassengerId helps us separate train and test. \n",
    "all_data.sort_values(by = 'PassengerId', inplace=True)\n",
    "\n",
    "## Separating train and test from all_data. \n",
    "train = all_data[:891]\n",
    "\n",
    "test = all_data[891:]\n",
    "\n",
    "# adding saved target variable with train. \n",
    "train['Survived'] = survivers\n",
    "\n",
    "missing_value = test[(test.Pclass == 3) & (test.Embarked == \"S\") & (test.Sex == \"male\")].Fare.mean()\n",
    "## replace the test.fare null values with test.fare mean\n",
    "test.Fare.fillna(missing_value, inplace=True)\n",
    "\n",
    "## dropping the three outliers where Fare is over $500 \n",
    "train = train[train.Fare < 500]\n",
    "\n",
    "# Placing 0 for female and \n",
    "# 1 for male in the \"Sex\" column. \n",
    "train['Sex'] = train.Sex.apply(lambda x: 0 if x == \"female\" else 1)\n",
    "test['Sex'] = test.Sex.apply(lambda x: 0 if x == \"female\" else 1)\n",
    "\n",
    "# Creating a new colomn with a \n",
    "train['name_length'] = [len(i) for i in train.Name]\n",
    "test['name_length'] = [len(i) for i in test.Name]\n",
    "\n",
    "def name_length_group(size):\n",
    "    a = ''\n",
    "    if (size <=20):\n",
    "        a = 'short'\n",
    "    elif (size <=35):\n",
    "        a = 'medium'\n",
    "    elif (size <=45):\n",
    "        a = 'good'\n",
    "    else:\n",
    "        a = 'long'\n",
    "    return a\n",
    "\n",
    "\n",
    "train['nLength_group'] = train['name_length'].map(name_length_group)\n",
    "test['nLength_group'] = test['name_length'].map(name_length_group)\n",
    "\n",
    "## Here \"map\" is python's built-in function. \n",
    "## \"map\" function basically takes a function and \n",
    "## returns an iterable list/tuple or in this case series. \n",
    "## However,\"map\" can also be used like map(function) e.g. map(name_length_group) \n",
    "## or map(function, iterable{list, tuple}) e.g. map(name_length_group, train[feature]]). \n",
    "## However, here we don't need to use parameter(\"size\") for name_length_group because when we \n",
    "## used the map function like \".map\" with a series before dot, we are basically hinting that series \n",
    "## and the iterable. This is similar to .append approach in python. list.append(a) meaning applying append on list. \n",
    "\n",
    "## cuts the column by given bins based on the range of name_length\n",
    "#group_names = ['short', 'medium', 'good', 'long']\n",
    "#train['name_len_group'] = pd.cut(train['name_length'], bins = 4, labels=group_names)\n",
    "\n",
    "## Title\n",
    "## get the title from the name\n",
    "train[\"title\"] = [i.split('.')[0] for i in train.Name]\n",
    "train[\"title\"] = [i.split(',')[1] for i in train.title]\n",
    "test[\"title\"] = [i.split('.')[0] for i in test.Name]\n",
    "test[\"title\"]= [i.split(',')[1] for i in test.title]\n",
    "\n",
    "#rare_title = ['the Countess','Capt','Lady','Sir','Jonkheer','Don','Major','Col']\n",
    "#train.Name = ['rare' for i in train.Name for j in rare_title if i == j]\n",
    "## train Data\n",
    "train[\"title\"] = [i.replace('Ms', 'Miss') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Mlle', 'Miss') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Mme', 'Mrs') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Dr', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Col', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Major', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Don', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Jonkheer', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Sir', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Lady', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Capt', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('the Countess', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Rev', 'rare') for i in train.title]\n",
    "\n",
    "\n",
    "\n",
    "#rare_title = ['the Countess','Capt','Lady','Sir','Jonkheer','Don','Major','Col']\n",
    "#train.Name = ['rare' for i in train.Name for j in rare_title if i == j]\n",
    "## test data\n",
    "test['title'] = [i.replace('Ms', 'Miss') for i in test.title]\n",
    "test['title'] = [i.replace('Dr', 'rare') for i in test.title]\n",
    "test['title'] = [i.replace('Col', 'rare') for i in test.title]\n",
    "test['title'] = [i.replace('Dona', 'rare') for i in test.title]\n",
    "test['title'] = [i.replace('Rev', 'rare') for i in test.title]\n",
    "\n",
    "## Family_size seems like a good feature to create\n",
    "train['family_size'] = train.SibSp + train.Parch+1\n",
    "test['family_size'] = test.SibSp + test.Parch+1\n",
    "\n",
    "def family_group(size):\n",
    "    a = ''\n",
    "    if (size <= 1):\n",
    "        a = 'loner'\n",
    "    elif (size <= 4):\n",
    "        a = 'small'\n",
    "    else:\n",
    "        a = 'large'\n",
    "    return a\n",
    "\n",
    "train['family_group'] = train['family_size'].map(family_group)\n",
    "test['family_group'] = test['family_size'].map(family_group)\n",
    "\n",
    "train['is_alone'] = [1 if i<2 else 0 for i in train.family_size]\n",
    "test['is_alone'] = [1 if i<2 else 0 for i in test.family_size]\n",
    "\n",
    "train.drop(['Ticket'], axis=1, inplace=True)\n",
    "\n",
    "test.drop(['Ticket'], axis=1, inplace=True)\n",
    "\n",
    "## Calculating fare based on family size. \n",
    "train['calculated_fare'] = train.Fare/train.family_size\n",
    "test['calculated_fare'] = test.Fare/test.family_size\n",
    "\n",
    "def fare_group(fare):\n",
    "    a= ''\n",
    "    if fare <= 4:\n",
    "        a = 'Very_low'\n",
    "    elif fare <= 10:\n",
    "        a = 'low'\n",
    "    elif fare <= 20:\n",
    "        a = 'mid'\n",
    "    elif fare <= 45:\n",
    "        a = 'high'\n",
    "    else:\n",
    "        a = \"very_high\"\n",
    "    return a\n",
    "\n",
    "train['fare_group'] = train['calculated_fare'].map(fare_group)\n",
    "test['fare_group'] = test['calculated_fare'].map(fare_group)\n",
    "\n",
    "#train['fare_group'] = pd.cut(train['calculated_fare'], bins = 4, labels=groups)\n",
    "\n",
    "train.drop(['PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "test.drop(['PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "train = pd.get_dummies(train, columns=['title',\"Pclass\", 'Cabin','Embarked','nLength_group', 'family_group', 'fare_group'], drop_first=False)\n",
    "test = pd.get_dummies(test, columns=['title',\"Pclass\",'Cabin','Embarked','nLength_group', 'family_group', 'fare_group'], drop_first=False)\n",
    "train.drop(['family_size','Name', 'Fare','name_length'], axis=1, inplace=True)\n",
    "test.drop(['Name','family_size',\"Fare\",'name_length'], axis=1, inplace=True)\n",
    "\n",
    "## rearranging the columns so that I can easily use the dataframe to predict the missing age values. \n",
    "train = pd.concat([train[[\"Survived\", \"Age\", \"Sex\",\"SibSp\",\"Parch\"]], train.loc[:,\"is_alone\":]], axis=1)\n",
    "test = pd.concat([test[[\"Age\", \"Sex\"]], test.loc[:,\"SibSp\":]], axis=1)\n",
    "\n",
    "## Importing RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "## writing a function that takes a dataframe with missing values and outputs it by filling the missing values. \n",
    "def completing_age(df):\n",
    "    ## gettting all the features except survived\n",
    "    age_df = df.loc[:,\"Age\":] \n",
    "    \n",
    "    temp_train = age_df.loc[age_df.Age.notnull()] ## df with age values\n",
    "    temp_test = age_df.loc[age_df.Age.isnull()] ## df without age values\n",
    "    \n",
    "    y = temp_train.Age.values ## setting target variables(age) in y \n",
    "    x = temp_train.loc[:, \"Sex\":].values\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_estimators=1500, n_jobs=-1)\n",
    "    rfr.fit(x, y)\n",
    "    \n",
    "    predicted_age = rfr.predict(temp_test.loc[:, \"Sex\":])\n",
    "    \n",
    "    df.loc[df.Age.isnull(), \"Age\"] = predicted_age\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "## Implementing the completing_age function in both train and test dataset. \n",
    "completing_age(train)\n",
    "completing_age(test);\n",
    "\n",
    "## create bins for age\n",
    "def age_group_fun(age):\n",
    "    a = ''\n",
    "    if age <= 1:\n",
    "        a = 'infant'\n",
    "    elif age <= 4: \n",
    "        a = 'toddler'\n",
    "    elif age <= 13:\n",
    "        a = 'child'\n",
    "    elif age <= 18:\n",
    "        a = 'teenager'\n",
    "    elif age <= 35:\n",
    "        a = 'Young_Adult'\n",
    "    elif age <= 45:\n",
    "        a = 'adult'\n",
    "    elif age <= 55:\n",
    "        a = 'middle_aged'\n",
    "    elif age <= 65:\n",
    "        a = 'senior_citizen'\n",
    "    else:\n",
    "        a = 'old'\n",
    "    return a\n",
    "        \n",
    "## Applying \"age_group_fun\" function to the \"Age\" column.\n",
    "train['age_group'] = train['Age'].map(age_group_fun)\n",
    "test['age_group'] = test['Age'].map(age_group_fun)\n",
    "\n",
    "## Creating dummies for \"age_group\" feature. \n",
    "train = pd.get_dummies(train,columns=['age_group'], drop_first=True)\n",
    "test = pd.get_dummies(test,columns=['age_group'], drop_first=True);\n",
    "\n",
    "\"\"\"train.drop('Age', axis=1, inplace=True)\n",
    "test.drop('Age', axis=1, inplace=True)\"\"\"\n",
    "\n",
    "# separating our independent and dependent variable\n",
    "X = train.drop(['Survived'], axis = 1)\n",
    "y = train[\"Survived\"]\n",
    "\n",
    "\n",
    "#age_filled_data_nor = NuclearNormMinimization().complete(df1)\n",
    "#Data_1 = pd.DataFrame(age_filled_data, columns = df1.columns)\n",
    "#pd.DataFrame(zip(Data[\"Age\"],Data_1[\"Age\"],df[\"Age\"]))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .33, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "## We will be using standardscaler to transform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "## transforming \"train_x\"\n",
    "train_x = sc.fit_transform(X_train)\n",
    "## transforming \"test_x\"\n",
    "test_x = sc.transform(X_test)\n",
    "\n",
    "## transforming \"The testset\"\n",
    "test = sc.transform(test)\n",
    "\n",
    "## changing calculated_fare type\n",
    "train.calculated_fare = train.calculated_fare.astype(float)\n",
    "\n",
    "## Using StratifiedShuffleSplit\n",
    "## We can use KFold, StratifiedShuffleSplit, StratiriedKFold or ShuffleSplit, They are all close cousins. look at sklearn userguide for more info.   \n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = .25, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "## Using standard scale for the whole dataset.\n",
    "\n",
    "## saving the feature names for decision tree display\n",
    "column_names = X.columns\n",
    "\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize = (12,10))\n",
    "plt.scatter(train.Age, train.Survived);\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel('Survival Status');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison - Our model vs built-in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our LogisticRegression model. \n",
    "from core.models import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, classification_report\n",
    "\n",
    "# import built-in LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression as LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model accuracy Score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81       177\n",
      "           1       0.69      0.82      0.75       117\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.78      0.79      0.78       294\n",
      "weighted avg       0.80      0.78      0.78       294\n",
      "\n",
      "Built in model accuracy Score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       177\n",
      "           1       0.75      0.74      0.74       117\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.79      0.79      0.79       294\n",
      "weighted avg       0.80      0.80      0.80       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################         Our LogisticRegression model                  ####################\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "## Once the model is trained we want to find out how well the model is performing, so we test the model. \n",
    "## we use \"test_x\" portion of the data(this data was not used to fit the model) to predict model outcome. \n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "## Once predicted we save that outcome in \"y_pred\" variable.\n",
    "## Then we compare the predicted value( \"y_pred\") and actual value(\"test_y\") to see how well our model is performing. \n",
    "print (\"Our model accuracy Score is: \\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "####################         Built-in LogisticRegression model                  ####################\n",
    "model = LR()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = model.predict(X_test)\n",
    "print (\"Built in model accuracy Score is: \\n\", classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Both models were trained and predicted on the same datasets. \n",
    "As we can see on the Classification Report there is a small difference between our model and built-in model.\n",
    "The results were very similar in favor of the built-in model. \n",
    "\n",
    "\n",
    "Taking into account that our model implementation was much more basic we can consider the results as satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
