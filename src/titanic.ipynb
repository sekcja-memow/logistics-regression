{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules for data analysis and data visualization. \n",
    "# Data analysis modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings                      ## importing warnings library. \n",
    "warnings.filterwarnings('ignore')    ## Ignore warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./datasets/titanic/train.csv\")\n",
    "test = pd.read_csv(\"./datasets/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>653</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kalvik, Mr. Johannes Halvorsen</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8475</td>\n",
       "      <td>8.4333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Pastcho (\"Pentcho\")</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349215</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dennis, Mr. Samuel</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21172</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>815</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Tomlin, Mr. Ernest Portage</td>\n",
       "      <td>male</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364499</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                  Name  \\\n",
       "652          653         0       3        Kalvik, Mr. Johannes Halvorsen   \n",
       "101          102         0       3      Petroff, Mr. Pastcho (\"Pentcho\")   \n",
       "320          321         0       3                    Dennis, Mr. Samuel   \n",
       "814          815         0       3            Tomlin, Mr. Ernest Portage   \n",
       "867          868         0       1  Roebling, Mr. Washington Augustus II   \n",
       "\n",
       "      Sex   Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
       "652  male  21.0      0      0       8475   8.4333   NaN        S  \n",
       "101  male   NaN      0      0     349215   7.8958   NaN        S  \n",
       "320  male  22.0      0      0  A/5 21172   7.2500   NaN        S  \n",
       "814  male  30.5      0      0     364499   8.0500   NaN        S  \n",
       "867  male  31.0      0      0   PC 17590  50.4958   A24        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Take a look at the overview of the dataset. \n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>2</td>\n",
       "      <td>Gale, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28664</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1106</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Ida Augusta Margareta</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347091</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>982</td>\n",
       "      <td>3</td>\n",
       "      <td>Dyker, Mrs. Adolf Fredrik (Anna Elisabeth Judi...</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>347072</td>\n",
       "      <td>13.9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>3</td>\n",
       "      <td>Robins, Mr. Alexander A</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 3337</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>990</td>\n",
       "      <td>3</td>\n",
       "      <td>Braf, Miss. Elin Ester Maria</td>\n",
       "      <td>female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347471</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "401         1293       2                                    Gale, Mr. Harry   \n",
       "214         1106       3             Andersson, Miss. Ida Augusta Margareta   \n",
       "90           982       3  Dyker, Mrs. Adolf Fredrik (Anna Elisabeth Judi...   \n",
       "25           917       3                            Robins, Mr. Alexander A   \n",
       "98           990       3                       Braf, Miss. Elin Ester Maria   \n",
       "\n",
       "        Sex   Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
       "401    male  38.0      1      0      28664  21.0000   NaN        S  \n",
       "214  female  38.0      4      2     347091   7.7750   NaN        S  \n",
       "90   female  22.0      1      0     347072  13.9000   NaN        S  \n",
       "25     male  50.0      1      0  A/5. 3337  14.5000   NaN        S  \n",
       "98   female  20.0      0      0     347471   7.8542   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving passenger id in advance in order to submit later. \n",
    "passengerid = test.PassengerId\n",
    "\n",
    "## Replacing the null values in the Embarked column with the mode. \n",
    "train.Embarked.fillna(\"C\", inplace=True)\n",
    "\n",
    "## Concat train and test into a variable \"all_data\"\n",
    "survivers = train.Survived\n",
    "\n",
    "train.drop([\"Survived\"],axis=1, inplace=True)\n",
    "\n",
    "all_data = pd.concat([train,test], ignore_index=False)\n",
    "\n",
    "## Assign all the null values to N\n",
    "all_data.Cabin.fillna(\"N\", inplace=True)\n",
    "\n",
    "all_data.Cabin = [i[0] for i in all_data.Cabin]\n",
    "\n",
    "with_N = all_data[all_data.Cabin == \"N\"]\n",
    "\n",
    "without_N = all_data[all_data.Cabin != \"N\"]\n",
    "\n",
    "all_data.groupby(\"Cabin\")['Fare'].mean().sort_values()\n",
    "\n",
    "def cabin_estimator(i):\n",
    "    a = 0\n",
    "    if i<16:\n",
    "        a = \"G\"\n",
    "    elif i>=16 and i<27:\n",
    "        a = \"F\"\n",
    "    elif i>=27 and i<38:\n",
    "        a = \"T\"\n",
    "    elif i>=38 and i<47:\n",
    "        a = \"A\"\n",
    "    elif i>= 47 and i<53:\n",
    "        a = \"E\"\n",
    "    elif i>= 53 and i<54:\n",
    "        a = \"D\"\n",
    "    elif i>=54 and i<116:\n",
    "        a = 'C'\n",
    "    else:\n",
    "        a = \"B\"\n",
    "    return a\n",
    "    \n",
    "\n",
    "##applying cabin estimator function. \n",
    "with_N['Cabin'] = with_N.Fare.apply(lambda x: cabin_estimator(x))\n",
    "\n",
    "## getting back train. \n",
    "all_data = pd.concat([with_N, without_N], axis=0)\n",
    "\n",
    "## PassengerId helps us separate train and test. \n",
    "all_data.sort_values(by = 'PassengerId', inplace=True)\n",
    "\n",
    "## Separating train and test from all_data. \n",
    "train = all_data[:891]\n",
    "\n",
    "test = all_data[891:]\n",
    "\n",
    "# adding saved target variable with train. \n",
    "train['Survived'] = survivers\n",
    "\n",
    "missing_value = test[(test.Pclass == 3) & (test.Embarked == \"S\") & (test.Sex == \"male\")].Fare.mean()\n",
    "## replace the test.fare null values with test.fare mean\n",
    "test.Fare.fillna(missing_value, inplace=True)\n",
    "\n",
    "## dropping the three outliers where Fare is over $500 \n",
    "train = train[train.Fare < 500]\n",
    "\n",
    "# Placing 0 for female and \n",
    "# 1 for male in the \"Sex\" column. \n",
    "train['Sex'] = train.Sex.apply(lambda x: 0 if x == \"female\" else 1)\n",
    "test['Sex'] = test.Sex.apply(lambda x: 0 if x == \"female\" else 1)\n",
    "\n",
    "# Creating a new colomn with a \n",
    "train['name_length'] = [len(i) for i in train.Name]\n",
    "test['name_length'] = [len(i) for i in test.Name]\n",
    "\n",
    "def name_length_group(size):\n",
    "    a = ''\n",
    "    if (size <=20):\n",
    "        a = 'short'\n",
    "    elif (size <=35):\n",
    "        a = 'medium'\n",
    "    elif (size <=45):\n",
    "        a = 'good'\n",
    "    else:\n",
    "        a = 'long'\n",
    "    return a\n",
    "\n",
    "\n",
    "train['nLength_group'] = train['name_length'].map(name_length_group)\n",
    "test['nLength_group'] = test['name_length'].map(name_length_group)\n",
    "\n",
    "## Here \"map\" is python's built-in function. \n",
    "## \"map\" function basically takes a function and \n",
    "## returns an iterable list/tuple or in this case series. \n",
    "## However,\"map\" can also be used like map(function) e.g. map(name_length_group) \n",
    "## or map(function, iterable{list, tuple}) e.g. map(name_length_group, train[feature]]). \n",
    "## However, here we don't need to use parameter(\"size\") for name_length_group because when we \n",
    "## used the map function like \".map\" with a series before dot, we are basically hinting that series \n",
    "## and the iterable. This is similar to .append approach in python. list.append(a) meaning applying append on list. \n",
    "\n",
    "## cuts the column by given bins based on the range of name_length\n",
    "#group_names = ['short', 'medium', 'good', 'long']\n",
    "#train['name_len_group'] = pd.cut(train['name_length'], bins = 4, labels=group_names)\n",
    "\n",
    "## Title\n",
    "## get the title from the name\n",
    "train[\"title\"] = [i.split('.')[0] for i in train.Name]\n",
    "train[\"title\"] = [i.split(',')[1] for i in train.title]\n",
    "test[\"title\"] = [i.split('.')[0] for i in test.Name]\n",
    "test[\"title\"]= [i.split(',')[1] for i in test.title]\n",
    "\n",
    "#rare_title = ['the Countess','Capt','Lady','Sir','Jonkheer','Don','Major','Col']\n",
    "#train.Name = ['rare' for i in train.Name for j in rare_title if i == j]\n",
    "## train Data\n",
    "train[\"title\"] = [i.replace('Ms', 'Miss') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Mlle', 'Miss') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Mme', 'Mrs') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Dr', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Col', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Major', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Don', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Jonkheer', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Sir', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Lady', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Capt', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('the Countess', 'rare') for i in train.title]\n",
    "train[\"title\"] = [i.replace('Rev', 'rare') for i in train.title]\n",
    "\n",
    "\n",
    "\n",
    "#rare_title = ['the Countess','Capt','Lady','Sir','Jonkheer','Don','Major','Col']\n",
    "#train.Name = ['rare' for i in train.Name for j in rare_title if i == j]\n",
    "## test data\n",
    "test['title'] = [i.replace('Ms', 'Miss') for i in test.title]\n",
    "test['title'] = [i.replace('Dr', 'rare') for i in test.title]\n",
    "test['title'] = [i.replace('Col', 'rare') for i in test.title]\n",
    "test['title'] = [i.replace('Dona', 'rare') for i in test.title]\n",
    "test['title'] = [i.replace('Rev', 'rare') for i in test.title]\n",
    "\n",
    "## Family_size seems like a good feature to create\n",
    "train['family_size'] = train.SibSp + train.Parch+1\n",
    "test['family_size'] = test.SibSp + test.Parch+1\n",
    "\n",
    "def family_group(size):\n",
    "    a = ''\n",
    "    if (size <= 1):\n",
    "        a = 'loner'\n",
    "    elif (size <= 4):\n",
    "        a = 'small'\n",
    "    else:\n",
    "        a = 'large'\n",
    "    return a\n",
    "\n",
    "train['family_group'] = train['family_size'].map(family_group)\n",
    "test['family_group'] = test['family_size'].map(family_group)\n",
    "\n",
    "train['is_alone'] = [1 if i<2 else 0 for i in train.family_size]\n",
    "test['is_alone'] = [1 if i<2 else 0 for i in test.family_size]\n",
    "\n",
    "train.drop(['Ticket'], axis=1, inplace=True)\n",
    "\n",
    "test.drop(['Ticket'], axis=1, inplace=True)\n",
    "\n",
    "## Calculating fare based on family size. \n",
    "train['calculated_fare'] = train.Fare/train.family_size\n",
    "test['calculated_fare'] = test.Fare/test.family_size\n",
    "\n",
    "def fare_group(fare):\n",
    "    a= ''\n",
    "    if fare <= 4:\n",
    "        a = 'Very_low'\n",
    "    elif fare <= 10:\n",
    "        a = 'low'\n",
    "    elif fare <= 20:\n",
    "        a = 'mid'\n",
    "    elif fare <= 45:\n",
    "        a = 'high'\n",
    "    else:\n",
    "        a = \"very_high\"\n",
    "    return a\n",
    "\n",
    "train['fare_group'] = train['calculated_fare'].map(fare_group)\n",
    "test['fare_group'] = test['calculated_fare'].map(fare_group)\n",
    "\n",
    "#train['fare_group'] = pd.cut(train['calculated_fare'], bins = 4, labels=groups)\n",
    "\n",
    "train.drop(['PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "test.drop(['PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "train = pd.get_dummies(train, columns=['title',\"Pclass\", 'Cabin','Embarked','nLength_group', 'family_group', 'fare_group'], drop_first=False)\n",
    "test = pd.get_dummies(test, columns=['title',\"Pclass\",'Cabin','Embarked','nLength_group', 'family_group', 'fare_group'], drop_first=False)\n",
    "train.drop(['family_size','Name', 'Fare','name_length'], axis=1, inplace=True)\n",
    "test.drop(['Name','family_size',\"Fare\",'name_length'], axis=1, inplace=True)\n",
    "\n",
    "## rearranging the columns so that I can easily use the dataframe to predict the missing age values. \n",
    "train = pd.concat([train[[\"Survived\", \"Age\", \"Sex\",\"SibSp\",\"Parch\"]], train.loc[:,\"is_alone\":]], axis=1)\n",
    "test = pd.concat([test[[\"Age\", \"Sex\"]], test.loc[:,\"SibSp\":]], axis=1)\n",
    "\n",
    "## Importing RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "## writing a function that takes a dataframe with missing values and outputs it by filling the missing values. \n",
    "def completing_age(df):\n",
    "    ## gettting all the features except survived\n",
    "    age_df = df.loc[:,\"Age\":] \n",
    "    \n",
    "    temp_train = age_df.loc[age_df.Age.notnull()] ## df with age values\n",
    "    temp_test = age_df.loc[age_df.Age.isnull()] ## df without age values\n",
    "    \n",
    "    y = temp_train.Age.values ## setting target variables(age) in y \n",
    "    x = temp_train.loc[:, \"Sex\":].values\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_estimators=1500, n_jobs=-1)\n",
    "    rfr.fit(x, y)\n",
    "    \n",
    "    predicted_age = rfr.predict(temp_test.loc[:, \"Sex\":])\n",
    "    \n",
    "    df.loc[df.Age.isnull(), \"Age\"] = predicted_age\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "## Implementing the completing_age function in both train and test dataset. \n",
    "completing_age(train)\n",
    "completing_age(test);\n",
    "\n",
    "## create bins for age\n",
    "def age_group_fun(age):\n",
    "    a = ''\n",
    "    if age <= 1:\n",
    "        a = 'infant'\n",
    "    elif age <= 4: \n",
    "        a = 'toddler'\n",
    "    elif age <= 13:\n",
    "        a = 'child'\n",
    "    elif age <= 18:\n",
    "        a = 'teenager'\n",
    "    elif age <= 35:\n",
    "        a = 'Young_Adult'\n",
    "    elif age <= 45:\n",
    "        a = 'adult'\n",
    "    elif age <= 55:\n",
    "        a = 'middle_aged'\n",
    "    elif age <= 65:\n",
    "        a = 'senior_citizen'\n",
    "    else:\n",
    "        a = 'old'\n",
    "    return a\n",
    "        \n",
    "## Applying \"age_group_fun\" function to the \"Age\" column.\n",
    "train['age_group'] = train['Age'].map(age_group_fun)\n",
    "test['age_group'] = test['Age'].map(age_group_fun)\n",
    "\n",
    "## Creating dummies for \"age_group\" feature. \n",
    "train = pd.get_dummies(train,columns=['age_group'], drop_first=True)\n",
    "test = pd.get_dummies(test,columns=['age_group'], drop_first=True);\n",
    "\n",
    "\"\"\"train.drop('Age', axis=1, inplace=True)\n",
    "test.drop('Age', axis=1, inplace=True)\"\"\"\n",
    "\n",
    "# separating our independent and dependent variable\n",
    "X = train.drop(['Survived'], axis = 1)\n",
    "y = train[\"Survived\"]\n",
    "\n",
    "\n",
    "#age_filled_data_nor = NuclearNormMinimization().complete(df1)\n",
    "#Data_1 = pd.DataFrame(age_filled_data, columns = df1.columns)\n",
    "#pd.DataFrame(zip(Data[\"Age\"],Data_1[\"Age\"],df[\"Age\"]))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .33, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "## We will be using standardscaler to transform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "## transforming \"train_x\"\n",
    "train_x = sc.fit_transform(X_train)\n",
    "## transforming \"test_x\"\n",
    "test_x = sc.transform(X_test)\n",
    "\n",
    "## transforming \"The testset\"\n",
    "test = sc.transform(test)\n",
    "\n",
    "## changing calculated_fare type\n",
    "train.calculated_fare = train.calculated_fare.astype(float)\n",
    "\n",
    "## Using StratifiedShuffleSplit\n",
    "## We can use KFold, StratifiedShuffleSplit, StratiriedKFold or ShuffleSplit, They are all close cousins. look at sklearn userguide for more info.   \n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = .25, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "## Using standard scale for the whole dataset.\n",
    "\n",
    "## saving the feature names for decision tree display\n",
    "column_names = X.columns\n",
    "\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize = (12,10))\n",
    "plt.scatter(train.Age, train.Survived);\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel('Survival Status');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model accuracy Score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81       177\n",
      "           1       0.69      0.82      0.75       117\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.78      0.79      0.78       294\n",
      "weighted avg       0.80      0.78      0.78       294\n",
      "\n",
      "Built in model accuracy Score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       177\n",
      "           1       0.75      0.73      0.74       117\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.79      0.78      0.79       294\n",
      "weighted avg       0.79      0.80      0.80       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import LogisticRegression model in python. \n",
    "from core.models import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "## call on the model object\n",
    "logreg = LogisticRegression()\n",
    "## fit the model with \"train_x\" and \"train_y\"\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "## Once the model is trained we want to find out how well the model is performing, so we test the model. \n",
    "## we use \"test_x\" portion of the data(this data was not used to fit the model) to predict model outcome. \n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "## Once predicted we save that outcome in \"y_pred\" variable.\n",
    "## Then we compare the predicted value( \"y_pred\") and actual value(\"test_y\") to see how well our model is performing. \n",
    "\n",
    "print (\"Our model accuracy Score is: \\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "model = LR()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = model.predict(X_test)\n",
    "print (\"Built in model accuracy Score is: \\n\", classification_report(y_test, y_pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
