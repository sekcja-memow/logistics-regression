{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic machine learning analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMS Titanic was the world's largest passenger ship when it entered service. Its terrible story is one of the best known disaster in the world. In our files we have the dataset which describes people taking a part in that voyage, we also know eather if they survived or not.\n",
    "Our goal is to check our model paying attention to answering the question: “what sorts of people were more likely to survive?”. First we need to preprocess the raw data, decide what sort of data will be useful, maybe we will need to create some data using those we have.  We will try to predict who would survive that disaster. At the end we will compare results our model to the built-in one of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading necessary modules for our task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules for data analysis and data visualization\n",
    "# data analysis modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import clock\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings                                                            # importing warnings library\n",
    "warnings.filterwarnings('ignore')                                          # ignore warning\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler                           # import standard scaler for transformation\n",
    "from sklearn.ensemble import RandomForestRegressor                         # import random dorest regressor\n",
    "from sklearn.model_selection import train_test_split                       # import train test split\n",
    "from sklearn.metrics import mean_absolute_error, classification_report     # import needed functions drom metrics\n",
    "\n",
    "# Models\n",
    "from core.models import LogisticRegression                                 # import our implementation of logistic regression\n",
    "from sklearn.linear_model import LogisticRegression as LR                  # import built-in logistic regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./datasets/titanic/titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable Name | Description                       | Type    |\n",
    "|---------------|-----------------------------------|---------|\n",
    "| PassengerId   | Passenger's ID                    | int64   |\n",
    "| Survived      | Survived (1) or died (0)          | int64   |\n",
    "| Pclass        | Passenger’s class                 | int64   |\n",
    "| Name          | Passenger’s name                  | object  |\n",
    "| Sex           | Passenger’s sex                   | object  |\n",
    "| Age           | Passenger’s age                   | float64 |\n",
    "| SibSp         | Number of siblings/spouses aboard | int64   |\n",
    "| Parch         | Number of parents/children aboard | int64   |\n",
    "| Ticket        | Ticket number                     | object  |\n",
    "| Fare          | Fare                              | float64 |\n",
    "| Cabin         | Cabin                             | object  |\n",
    "| Embarked      | Port of embarkation               | object  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Notes\n",
    "\n",
    "pclass: A proxy for socio-economic status (SES) 1st = Upper 2nd = Middle 3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way... Sibling = brother, sister, stepbrother, stepsister Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way... Parent = mother, father Child = daughter, son, stepdaughter, stepson Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of our data samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: \t (891, 12)\n"
     ]
    }
   ],
   "source": [
    "print('dataset shape: \\t', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 samples of the dataset, short meaning of particular columns was described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Shellard, Mr. Frederick William</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 6212</td>\n",
       "      <td>15.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>811</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Alexander, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3474</td>\n",
       "      <td>7.8875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Mr. Richard George</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>29104</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Nysten, Miss. Anna Sofia</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347081</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>430</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Pickard, Mr. Berk (Berk Trembisky)</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 392078</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>E10</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Niskanen, Mr. Juha</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101289</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>476</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Clifford, Mr. George Quincy</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110465</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>A14</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>338</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Burns, Miss. Elizabeth Margaret</td>\n",
       "      <td>female</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16966</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>E40</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Miss. Mary</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14312</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>848</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markoff, Mr. Marin</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349213</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                Name  \\\n",
       "497          498         0       3     Shellard, Mr. Frederick William   \n",
       "810          811         0       3              Alexander, Mr. William   \n",
       "529          530         0       2         Hocking, Mr. Richard George   \n",
       "141          142         1       3            Nysten, Miss. Anna Sofia   \n",
       "429          430         1       3  Pickard, Mr. Berk (Berk Trembisky)   \n",
       "400          401         1       3                  Niskanen, Mr. Juha   \n",
       "475          476         0       1         Clifford, Mr. George Quincy   \n",
       "337          338         1       1     Burns, Miss. Elizabeth Margaret   \n",
       "573          574         1       3                   Kelly, Miss. Mary   \n",
       "847          848         0       3                  Markoff, Mr. Marin   \n",
       "\n",
       "        Sex   Age  SibSp  Parch             Ticket      Fare Cabin Embarked  \n",
       "497    male   NaN      0      0          C.A. 6212   15.1000   NaN        S  \n",
       "810    male  26.0      0      0               3474    7.8875   NaN        S  \n",
       "529    male  23.0      2      1              29104   11.5000   NaN        S  \n",
       "141  female  22.0      0      0             347081    7.7500   NaN        S  \n",
       "429    male  32.0      0      0  SOTON/O.Q. 392078    8.0500   E10        S  \n",
       "400    male  39.0      0      0  STON/O 2. 3101289    7.9250   NaN        S  \n",
       "475    male   NaN      0      0             110465   52.0000   A14        S  \n",
       "337  female  41.0      0      0              16966  134.5000   E40        C  \n",
       "573  female   NaN      0      0              14312    7.7500   NaN        Q  \n",
       "847    male  35.0      0      0             349213    7.8958   NaN        C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the null values in the Embarked column with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Embarked.fillna(\"C\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating cabin name for NaN, we do it using our fare column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Cabin.fillna(\"N\", inplace=True)\n",
    "data.Cabin = [i[0] for i in data.Cabin]\n",
    "\n",
    "with_N = data[data.Cabin == \"N\"]\n",
    "without_N = data[data.Cabin != \"N\"]                   \n",
    "data.groupby(\"Cabin\")['Fare'].mean().sort_values()    \n",
    "\n",
    "def cabin_estimator(i):\n",
    "    a = 0\n",
    "    if i<16:\n",
    "        a = \"G\"\n",
    "    elif i>=16 and i<27:\n",
    "        a = \"F\"\n",
    "    elif i>=27 and i<38:\n",
    "        a = \"T\"\n",
    "    elif i>=38 and i<47:\n",
    "        a = \"A\"\n",
    "    elif i>= 47 and i<53:\n",
    "        a = \"E\"\n",
    "    elif i>= 53 and i<54:\n",
    "        a = \"D\"\n",
    "    elif i>=54 and i<116:\n",
    "        a = 'C'\n",
    "    else:\n",
    "        a = \"B\"\n",
    "    return a\n",
    "\n",
    "with_N['Cabin'] = with_N.Fare.apply(lambda x: cabin_estimator(x))\n",
    "data = pd.concat([with_N, without_N], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the fare null values with fare mean and remove outliers with earlier checked value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value = data[(data.Pclass == 3) & (data.Embarked == \"S\") & (data.Sex == \"male\")].Fare.mean()\n",
    "data.Fare.fillna(missing_value, inplace=True)\n",
    "data = data[data.Fare < 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex column mapping. We use 0 for female and 1 for male so that our model could learn on that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sex'] = data.Sex.map({'male': 1, 'female': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do some operations on names. We will make some classes of names which we will use later for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting title of name column \n",
    "\n",
    "data[\"title\"] = [i.split('.')[0] for i in data.Name]\n",
    "data[\"title\"] = [i.split(',')[1] for i in data.title]\n",
    "\n",
    "\n",
    "# we have to map some special names \n",
    "data[\"title\"] = [i.replace('Ms', 'Miss') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Mlle', 'Miss') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Mme', 'Mrs') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Dr', 'rare') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Col', 'rare') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Major', 'rare') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Don', 'rare') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Jonkheer', 'rare') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Sir', 'rare') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Lady', 'rare') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Capt', 'rare') for i in data.title]\n",
    "data[\"title\"] = [i.replace('the Countess', 'rare') for i in data.title]\n",
    "data[\"title\"] = [i.replace('Rev', 'rare') for i in data.title]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking who is alone on the board. We think it may have an effect on results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['family_size'] = data.SibSp + data.Parch+1\n",
    "\n",
    "def family_group(size):\n",
    "    a = ''\n",
    "    if (size <= 1):\n",
    "        a = 'loner'\n",
    "    elif (size <= 4):\n",
    "        a = 'small'\n",
    "    else:\n",
    "        a = 'large'\n",
    "    return a\n",
    "\n",
    "data['family_group'] = data['family_size'].map(family_group)\n",
    "data['is_alone'] = [1 if i<2 else 0 for i in data.family_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting info about ticket, it's just redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating fare based on family size and creating fare group column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['calculated_fare'] = data.Fare/data.family_size\n",
    "\n",
    "def fare_group(fare):\n",
    "    a= ''\n",
    "    if fare <= 4:\n",
    "        a = 'Very_low'\n",
    "    elif fare <= 10:\n",
    "        a = 'low'\n",
    "    elif fare <= 20:\n",
    "        a = 'mid'\n",
    "    elif fare <= 45:\n",
    "        a = 'high'\n",
    "    else:\n",
    "        a = \"very_high\"\n",
    "    return a\n",
    "\n",
    "data['fare_group'] = data['calculated_fare'].map(fare_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passenger ID is redundant information, it won't help us in prediction, it's just absolutely random string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make the data which we have made earlier. Get dummies will help our model make use of our categorical data. Later we can drop redundant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['title','Pclass', 'Cabin','Embarked', 'family_group', 'fare_group'], drop_first=False)\n",
    "\n",
    "data.drop(['family_size','Name', 'Fare'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to predict age for cells where the value is NaN so that we can make use of age later on too. For this task we will use built-in predictor: random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearranging the columns so that we can easily use the dataframe to predict the missing age val\n",
    "data = pd.concat([data[[\"Survived\", \"Age\", \"Sex\",\"SibSp\",\"Parch\"]], data.loc[:,\"is_alone\":]], axis=1)\n",
    "\n",
    "def predict_age(df):\n",
    "    age_df = df.loc[:,\"Age\":]                            # gettting all the features except survived\n",
    "    \n",
    "    temp_train = age_df.loc[age_df.Age.notnull()]        # df with age values\n",
    "    temp_test = age_df.loc[age_df.Age.isnull()]          # df without age values\n",
    "    \n",
    "    y = temp_train.Age.values                            # setting target variables(age) in y \n",
    "    x = temp_train.loc[:, \"Sex\":].values\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_estimators=1500, n_jobs=-1)\n",
    "    rfr.fit(x, y)\n",
    "    \n",
    "    predicted_age = rfr.predict(temp_test.loc[:, \"Sex\":])\n",
    "    \n",
    "    df.loc[df.Age.isnull(), \"Age\"] = predicted_age\n",
    "    return df\n",
    "\n",
    "# age prediction for null cells\n",
    "data = predict_age(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we don't have any NaN cells we can get age group for everyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_group(age):\n",
    "    a = ''\n",
    "    if age <= 1:\n",
    "        a = 'infant'\n",
    "    elif age <= 4: \n",
    "        a = 'toddler'\n",
    "    elif age <= 13:\n",
    "        a = 'child'\n",
    "    elif age <= 18:\n",
    "        a = 'teenager'\n",
    "    elif age <= 35:\n",
    "        a = 'Young_Adult'\n",
    "    elif age <= 45:\n",
    "        a = 'adult'\n",
    "    elif age <= 55:\n",
    "        a = 'middle_aged'\n",
    "    elif age <= 65:\n",
    "        a = 'senior_citizen'\n",
    "    else:\n",
    "        a = 'old'\n",
    "    return a\n",
    "        \n",
    "# applying \"age_group_fun\" function to the \"Age\" column\n",
    "data['age_group'] = data['Age'].map(age_group)\n",
    "\n",
    "# creating dummies for \"age_group\" feature\n",
    "data = pd.get_dummies(data,columns=['age_group'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see results of work we have made so far. In these 10 samples of our dataset we can see 42 columns and a lot of zeros in there. It is result of get dummies functions which \"gives\" us one only under a category which the row belongs to and zeros under other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>calculated_fare</th>\n",
       "      <th>title_ Master</th>\n",
       "      <th>title_ Miss</th>\n",
       "      <th>title_ Mr</th>\n",
       "      <th>...</th>\n",
       "      <th>fare_group_mid</th>\n",
       "      <th>fare_group_very_high</th>\n",
       "      <th>age_group_adult</th>\n",
       "      <th>age_group_child</th>\n",
       "      <th>age_group_infant</th>\n",
       "      <th>age_group_middle_aged</th>\n",
       "      <th>age_group_old</th>\n",
       "      <th>age_group_senior_citizen</th>\n",
       "      <th>age_group_teenager</th>\n",
       "      <th>age_group_toddler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.237500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>43.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.525000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0</td>\n",
       "      <td>45.366579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.225000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived        Age  Sex  SibSp  Parch  is_alone  calculated_fare  \\\n",
       "823         1  27.000000    0      0      1         0         6.237500   \n",
       "438         0  64.000000    1      1      4         0        43.833333   \n",
       "112         0  22.000000    1      0      0         1         8.050000   \n",
       "508         0  28.000000    1      0      0         1        22.525000   \n",
       "711         0  45.366579    1      0      0         1        26.550000   \n",
       "695         0  52.000000    1      0      0         1        13.500000   \n",
       "806         0  39.000000    1      0      0         1         0.000000   \n",
       "316         1  24.000000    0      1      0         0        13.000000   \n",
       "217         0  42.000000    1      1      0         0        13.500000   \n",
       "350         0  23.000000    1      0      0         1         9.225000   \n",
       "\n",
       "     title_ Master  title_ Miss  title_ Mr  ...  fare_group_mid  \\\n",
       "823              0            0          0  ...               0   \n",
       "438              0            0          1  ...               0   \n",
       "112              0            0          1  ...               0   \n",
       "508              0            0          1  ...               0   \n",
       "711              0            0          1  ...               0   \n",
       "695              0            0          1  ...               1   \n",
       "806              0            0          1  ...               0   \n",
       "316              0            0          0  ...               1   \n",
       "217              0            0          1  ...               1   \n",
       "350              0            0          1  ...               0   \n",
       "\n",
       "     fare_group_very_high  age_group_adult  age_group_child  age_group_infant  \\\n",
       "823                     0                0                0                 0   \n",
       "438                     0                0                0                 0   \n",
       "112                     0                0                0                 0   \n",
       "508                     0                0                0                 0   \n",
       "711                     0                0                0                 0   \n",
       "695                     0                0                0                 0   \n",
       "806                     0                1                0                 0   \n",
       "316                     0                0                0                 0   \n",
       "217                     0                1                0                 0   \n",
       "350                     0                0                0                 0   \n",
       "\n",
       "     age_group_middle_aged  age_group_old  age_group_senior_citizen  \\\n",
       "823                      0              0                         0   \n",
       "438                      0              0                         1   \n",
       "112                      0              0                         0   \n",
       "508                      0              0                         0   \n",
       "711                      1              0                         0   \n",
       "695                      1              0                         0   \n",
       "806                      0              0                         0   \n",
       "316                      0              0                         0   \n",
       "217                      0              0                         0   \n",
       "350                      0              0                         0   \n",
       "\n",
       "     age_group_teenager  age_group_toddler  \n",
       "823                   0                  0  \n",
       "438                   0                  0  \n",
       "112                   0                  0  \n",
       "508                   0                  0  \n",
       "711                   0                  0  \n",
       "695                   0                  0  \n",
       "806                   0                  0  \n",
       "316                   0                  0  \n",
       "217                   0                  0  \n",
       "350                   0                  0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step: creating final datasets, creating learning data and labels for the data. Later we need to split the data for training dataset and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our final prediction datasets\n",
    "X = data.drop(['Survived'], axis = 1)\n",
    "y = data['Survived']\n",
    "\n",
    "# train-test split with test size = 0.2 and random state = 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison - Our model vs built-in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her is a final part of our work: checking the results. We will create the model, train it with the data we created before and check its results using classification report.\n",
    "Later on we will compare it with built-in model of logistic regression and measure training and prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model accuracy Score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       115\n",
      "           1       0.68      0.83      0.74        63\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.78      0.80      0.79       178\n",
      "weighted avg       0.81      0.80      0.80       178\n",
      " \n",
      "\n",
      "Built in model accuracy Score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       115\n",
      "           1       0.74      0.76      0.75        63\n",
      "\n",
      "    accuracy                           0.82       178\n",
      "   macro avg       0.80      0.81      0.80       178\n",
      "weighted avg       0.82      0.82      0.82       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating logistic regression model of our implementation\n",
    "start_my_lr = clock()\n",
    "our_model = LogisticRegression()\n",
    "\n",
    "# fit the model with \"train_x\" and \"train_y\"\n",
    "our_model.fit(X_train,y_train)\n",
    "\n",
    "# once the model is trained we want to find out how well the model is performing, so we test the model\n",
    "# we use \"test_x\" portion of the data (this data was not used to fit the model) to predict model outcome\n",
    "y_pred = our_model.predict(X_test)\n",
    "\n",
    "end_my_lr = clock()\n",
    "\n",
    "# once predicted we save that outcome in \"y_pred\" variable.\n",
    "# then we compare the predicted value (\"y_pred\") and actual value (\"test_y\") to see how well our model is performing\n",
    "print (\"Our model accuracy Score is: \\n\", classification_report(y_test, y_pred), '\\n')\n",
    "\n",
    "# when we get the result of our model we can compare it to built-in version of logistic regression\n",
    "# we have to create and train the model on the same data, then predict the outcome and see the result\n",
    "start_bi_lr = clock()\n",
    "bi_model = LR()\n",
    "bi_model.fit(X_train, y_train)\n",
    "y_pred1 = bi_model.predict(X_test)\n",
    "end_bi_lr = clock()\n",
    "print (\"Built in model accuracy Score is: \\n\", classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our logistic regression time: \t0.16573189999999993\n",
      "Built-in logistic regression time: \t0.07042479999999962\n"
     ]
    }
   ],
   "source": [
    "my_lr_time = end_my_lr - start_my_lr\n",
    "bi_lr_time = end_bi_lr - start_bi_lr\n",
    "\n",
    "print(f'Our logistic regression time: \\t{my_lr_time}')\n",
    "print(f'Built-in logistic regression time: \\t{bi_lr_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above we got two times bigger time from our logistic regression in comparison to built-in model. That's a lot but we will think about it in summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Both models were trained and predicted on the same datasets. As we can see on the Classification Report there is a small difference between our model and built-in model. The results were very similar in favor of the built-in model.\n",
    "\n",
    "In last cell we can see that there is about two times bigger processing time in our logistic regression model. That is actually a lot, especially when we think about predicting some bigger amounts of data. On the other hand remember that our model is really simple representation of logistic regression and doesn't have any special features which would make it more efficient.\n",
    "\n",
    "Taking into account that our model implementation was much more basic, even taking the time result into account we can consider the results as satisfactory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
