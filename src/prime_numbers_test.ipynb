{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.19.4 in d:\\p\\anaconda\\lib\\site-packages (from -r ../requirements.txt (line 1)) (1.19.4)\n",
      "Requirement already satisfied: idx2numpy>=1.2.3 in d:\\p\\anaconda\\lib\\site-packages (from -r ../requirements.txt (line 2)) (1.2.3)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\karol\\appdata\\roaming\\python\\python37\\site-packages (from -r ../requirements.txt (line 3)) (2.25.0)\n",
      "Requirement already satisfied: sklearn>=0.0 in c:\\users\\karol\\appdata\\roaming\\python\\python37\\site-packages (from -r ../requirements.txt (line 4)) (0.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.2 in d:\\p\\anaconda\\lib\\site-packages (from -r ../requirements.txt (line 5)) (3.3.3)\n",
      "Requirement already satisfied: six in d:\\p\\anaconda\\lib\\site-packages (from idx2numpy>=1.2.3->-r ../requirements.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\p\\anaconda\\lib\\site-packages (from requests>=2.25.0->-r ../requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\p\\anaconda\\lib\\site-packages (from requests>=2.25.0->-r ../requirements.txt (line 3)) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\p\\anaconda\\lib\\site-packages (from requests>=2.25.0->-r ../requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\p\\anaconda\\lib\\site-packages (from requests>=2.25.0->-r ../requirements.txt (line 3)) (1.25.9)\n",
      "Requirement already satisfied: scikit-learn in d:\\p\\anaconda\\lib\\site-packages (from sklearn>=0.0->-r ../requirements.txt (line 4)) (0.22.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\p\\anaconda\\lib\\site-packages (from matplotlib>=3.3.2->-r ../requirements.txt (line 5)) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\p\\anaconda\\lib\\site-packages (from matplotlib>=3.3.2->-r ../requirements.txt (line 5)) (7.0.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\p\\anaconda\\lib\\site-packages (from matplotlib>=3.3.2->-r ../requirements.txt (line 5)) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\p\\anaconda\\lib\\site-packages (from matplotlib>=3.3.2->-r ../requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\p\\anaconda\\lib\\site-packages (from matplotlib>=3.3.2->-r ../requirements.txt (line 5)) (0.10.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\p\\anaconda\\lib\\site-packages (from scikit-learn->sklearn>=0.0->-r ../requirements.txt (line 4)) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in d:\\p\\anaconda\\lib\\site-packages (from scikit-learn->sklearn>=0.0->-r ../requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: setuptools in d:\\p\\anaconda\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=3.3.2->-r ../requirements.txt (line 5)) (45.2.0.post20200210)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'd:\\p\\anaconda\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# required packages installation\n",
    "\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model and required components\n",
    "from core.models import LogisticRegression\n",
    "from core.optimizers import *\n",
    "from core.regularizers import *\n",
    "\n",
    "# imports for data loading\n",
    "from requests import get\n",
    "import idx2numpy\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# import for data processing and analysis\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# warnings ignoring\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data downloading and preprocessing function\n",
    "        \n",
    "def load_data():\n",
    "    \n",
    "    urls = []\n",
    "    urls.append('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')\n",
    "    urls.append('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')\n",
    "    urls.append('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')\n",
    "    urls.append('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')\n",
    "    \n",
    "    print('Downloading data...')\n",
    "    responses = [get(url, allow_redirects=True) for url in urls]\n",
    "    \n",
    "    names = ['train_images', 'train_labels', 'test_images', 'test_labels']\n",
    "    \n",
    "    for index, response in enumerate(responses):\n",
    "        open(f'./datasets/prime_numbers/{names[index]}-gz', 'wb').write(response.content)\n",
    "        \n",
    "    print('Unpacking files...')\n",
    "    for name in names:\n",
    "        with gzip.open(f'./datasets/prime_numbers/{name}-gz', 'rb') as f_in:\n",
    "            with open(f'./datasets/prime_numbers/{name}', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    " \n",
    "    for name in names:\n",
    "        os.remove(f'./datasets/prime_numbers/{name}-gz')\n",
    "\n",
    "    f_read = open('./datasets/prime_numbers/train-images','rb')\n",
    "    X_train = idx2numpy.convert_from_file(f_read)\n",
    "\n",
    "    f_read = open('./datasets/prime_numbers/train-labels', 'rb')\n",
    "    y_train = idx2numpy.convert_from_file(f_read)\n",
    "\n",
    "    f_read = open('./datasets/prime_numbers/test-images', 'rb')\n",
    "    X_test = idx2numpy.convert_from_file(f_read)\n",
    "    \n",
    "    f_read = open('./datasets/prime_numbers/test-labels', 'rb')\n",
    "    y_test = idx2numpy.convert_from_file(f_read)\n",
    "\n",
    "\n",
    "    X_train = X_train.reshape(len(X_train), 784)\n",
    "    X_test = X_test.reshape(len(X_test), 784)\n",
    "\n",
    "\n",
    "    tmp_X = []\n",
    "    tmp_y = []\n",
    "\n",
    "    for index,label in enumerate(y_train):\n",
    "        if label in [2,3,5,7]:\n",
    "            tmp_X.append(X_train[index])\n",
    "            tmp_y.append(1)\n",
    "        elif label in [4,6,8,9]:\n",
    "            tmp_X.append(X_train[index])\n",
    "            tmp_y.append(0)\n",
    "\n",
    "    tmp_X_test = []\n",
    "    tmp_y_test = []\n",
    "\n",
    "    for index,label in enumerate(y_test):\n",
    "        if label in [2,3,5,7]:\n",
    "            tmp_X_test.append(X_test[index])\n",
    "            tmp_y_test.append(1)\n",
    "        elif label in [4,6,8,9]:\n",
    "            tmp_X_test.append(X_test[index])\n",
    "            tmp_y_test.append(0)\n",
    "\n",
    "\n",
    "    X_train = np.array(tmp_X)\n",
    "    X_test = np.array(tmp_X_test)\n",
    "    y_train = np.array(tmp_y)\n",
    "    y_test = np.array(tmp_y_test)\n",
    "    \n",
    "    print('Data loading finished!')\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Unpacking files...\n",
      "Data loading finished!\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "\n",
    "X_train_raw, X_test, y_train_raw, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of our training samples: \t 47335\n",
      "Num of our testing samples: \t 7885\n"
     ]
    }
   ],
   "source": [
    "print(\"Num of our training samples: \\t\", X_train_raw.shape[0])\n",
    "print(\"Num of our testing samples: \\t\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# single record visualization \n",
    "\n",
    "number = np.reshape(X_train_raw[0], (28,28))\n",
    "plt.imshow(number, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# training sample\n",
    "\n",
    "print(X_train_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# some examples with labels\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "for i, (X, label) in enumerate(zip(X_train_raw[0:8], y_train_raw[0:8])):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.title(f'Label: {label}', fontsize = 20)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.reshape(X, (28,28)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking num of samples we want to train aur model on \n",
    "\n",
    "num_of_samples = 10000\n",
    "\n",
    "X_train = X_train_raw[:num_of_samples]\n",
    "y_train = y_train_raw[:num_of_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default model efficienty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation score determination on model with default parameters\n",
    "\n",
    "model = LogisticRegression()\n",
    "result = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result\n",
      "[0.9125 0.881  0.912  0.8985 0.82  ]\n",
      "Cross validation mean\n",
      "0.8847999999999999\n"
     ]
    }
   ],
   "source": [
    "print('Cross validation result')\n",
    "print(result)\n",
    "print('Cross validation mean')\n",
    "print(np.mean(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Classification report is used to measure the quality of predictions from a classification algorithm. \n",
    "##### Main scores: \n",
    "##### **Precision** – What percent of your predictions were correct? (Precision = TP/(TP + FP))\n",
    "##### **Recall** – What percent of the positive cases did you catch? (Recall = TP/(TP+FN))\n",
    "##### **F1 score** – What percent of positive predictions were correct? (F1 Score = 2*(Recall * Precision) / (Recall + Precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending all optimizers to check their efficiency\n",
    "\n",
    "optimizers = []\n",
    "\n",
    "optimizers.append(GradientDescentOptimizer())\n",
    "optimizers.append(MomentumGradientDescentOptimizer())\n",
    "optimizers.append(AdaGradOptimizer())\n",
    "optimizers.append(RMSPropOptimizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                 GradientDescentOptimizer(learning_rate: 0.03)                  \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      3923\n",
      "           1       0.91      0.91      0.91      3962\n",
      "\n",
      "    accuracy                           0.91      7885\n",
      "   macro avg       0.91      0.91      0.91      7885\n",
      "weighted avg       0.91      0.91      0.91      7885\n",
      "\n",
      "================================================================================\n",
      "   MomentumGradientDescentOptimizer(learning_rate: 0.03, momentum_rate: 0.9)    \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89      3923\n",
      "           1       0.86      0.94      0.90      3962\n",
      "\n",
      "    accuracy                           0.90      7885\n",
      "   macro avg       0.90      0.90      0.90      7885\n",
      "weighted avg       0.90      0.90      0.90      7885\n",
      "\n",
      "================================================================================\n",
      "             AdaGradOptimizer(learning_rate: 0.03, epsilon: 1e-07)              \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      3923\n",
      "           1       0.92      0.91      0.91      3962\n",
      "\n",
      "    accuracy                           0.91      7885\n",
      "   macro avg       0.91      0.91      0.91      7885\n",
      "weighted avg       0.91      0.91      0.91      7885\n",
      "\n",
      "================================================================================\n",
      "        RMSPropOptimizer(learning_rate: 0.03, beta: 0.9, epsilon: 1e-07)        \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      3923\n",
      "           1       0.92      0.92      0.92      3962\n",
      "\n",
      "    accuracy                           0.92      7885\n",
      "   macro avg       0.92      0.92      0.92      7885\n",
      "weighted avg       0.92      0.92      0.92      7885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# regularizer=RidgeRegularizer(), num_iterations=300, threshold=0.5, fit_intercept=True, verbose=False\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    model = LogisticRegression(optimizer = optimizer)\n",
    "    model.fit(X_train_raw, y_train_raw)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"=\"*80)\n",
    "    print(str(optimizer).center(80, ' '))\n",
    "    print(\"=\"*80)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizers testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending all regularizers to check their efficiency\n",
    "\n",
    "regularizers = []\n",
    "\n",
    "regularizers.append(LassoRegularizer())\n",
    "regularizers.append(RidgeRegularizer())\n",
    "regularizers.append(ElasticNetRegularizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "        RMSPropOptimizer(learning_rate: 0.03, beta: 0.9, epsilon: 1e-07)        \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      3923\n",
      "           1       0.90      0.94      0.92      3962\n",
      "\n",
      "    accuracy                           0.92      7885\n",
      "   macro avg       0.92      0.91      0.91      7885\n",
      "weighted avg       0.92      0.92      0.91      7885\n",
      "\n",
      "================================================================================\n",
      "        RMSPropOptimizer(learning_rate: 0.03, beta: 0.9, epsilon: 1e-07)        \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89      3923\n",
      "           1       0.97      0.78      0.87      3962\n",
      "\n",
      "    accuracy                           0.88      7885\n",
      "   macro avg       0.89      0.88      0.88      7885\n",
      "weighted avg       0.89      0.88      0.88      7885\n",
      "\n",
      "================================================================================\n",
      "        RMSPropOptimizer(learning_rate: 0.03, beta: 0.9, epsilon: 1e-07)        \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      3923\n",
      "           1       0.94      0.89      0.92      3962\n",
      "\n",
      "    accuracy                           0.92      7885\n",
      "   macro avg       0.92      0.92      0.92      7885\n",
      "weighted avg       0.92      0.92      0.92      7885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# optimizer=RMSPropOptimizer, num_iterations=300, threshold=0.5, fit_intercept=True, verbose=False\n",
    "\n",
    "for regularizer in regularizers:\n",
    "    model = LogisticRegression(regularizer = regularizer)\n",
    "    model.fit(X_train_raw, y_train_raw)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"=\"*80)\n",
    "    print(str(optimizer).center(80, ' '))\n",
    "    print(\"=\"*80)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of samples testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We should also test how numbers of samples affects on our scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all samples:  47335\n"
     ]
    }
   ],
   "source": [
    "print('Number of all samples: ', len(X_train_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = [5, 100, 500, 1000, 2000, 5000, 10000, 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\" 5 samples \"====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.63      3923\n",
      "           1       0.64      0.75      0.69      3962\n",
      "\n",
      "    accuracy                           0.67      7885\n",
      "   macro avg       0.67      0.67      0.66      7885\n",
      "weighted avg       0.67      0.67      0.66      7885\n",
      "\n",
      "===================\" 100 samples \"===================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82      3923\n",
      "           1       0.87      0.72      0.79      3962\n",
      "\n",
      "    accuracy                           0.81      7885\n",
      "   macro avg       0.82      0.81      0.81      7885\n",
      "weighted avg       0.82      0.81      0.81      7885\n",
      "\n",
      "===================\" 1000 samples \"==================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      3923\n",
      "           1       0.83      0.93      0.88      3962\n",
      "\n",
      "    accuracy                           0.87      7885\n",
      "   macro avg       0.88      0.87      0.87      7885\n",
      "weighted avg       0.88      0.87      0.87      7885\n",
      "\n",
      "===================\" 2000 samples \"==================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83      3923\n",
      "           1       0.97      0.62      0.76      3962\n",
      "\n",
      "    accuracy                           0.80      7885\n",
      "   macro avg       0.84      0.80      0.79      7885\n",
      "weighted avg       0.85      0.80      0.79      7885\n",
      "\n",
      "===================\" 5000 samples \"==================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      3923\n",
      "           1       0.95      0.84      0.89      3962\n",
      "\n",
      "    accuracy                           0.90      7885\n",
      "   macro avg       0.90      0.90      0.90      7885\n",
      "weighted avg       0.90      0.90      0.90      7885\n",
      "\n",
      "==================\" 10000 samples \"==================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      3923\n",
      "           1       0.94      0.88      0.91      3962\n",
      "\n",
      "    accuracy                           0.91      7885\n",
      "   macro avg       0.91      0.91      0.91      7885\n",
      "weighted avg       0.91      0.91      0.91      7885\n",
      "\n",
      "==================\" 20000 samples \"==================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      3923\n",
      "           1       0.90      0.93      0.92      3962\n",
      "\n",
      "    accuracy                           0.91      7885\n",
      "   macro avg       0.91      0.91      0.91      7885\n",
      "weighted avg       0.91      0.91      0.91      7885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num in num_of_samples:\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_raw[:num], y_train_raw[:num])\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(('\" '+ str(num) +' samples \"').center(53, '='))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of iterations testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iterations = [100, 300, 500, 1000, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\" 100 iterations \"=================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88      3923\n",
      "           1       0.84      0.96      0.89      3962\n",
      "\n",
      "    accuracy                           0.89      7885\n",
      "   macro avg       0.89      0.89      0.89      7885\n",
      "weighted avg       0.89      0.89      0.89      7885\n",
      "\n",
      "==================\" 300 iterations \"=================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.24      0.39      3923\n",
      "           1       0.57      0.99      0.72      3962\n",
      "\n",
      "    accuracy                           0.62      7885\n",
      "   macro avg       0.77      0.62      0.56      7885\n",
      "weighted avg       0.77      0.62      0.56      7885\n",
      "\n",
      "==================\" 500 iterations \"=================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      3923\n",
      "           1       0.90      0.93      0.91      3962\n",
      "\n",
      "    accuracy                           0.91      7885\n",
      "   macro avg       0.91      0.91      0.91      7885\n",
      "weighted avg       0.91      0.91      0.91      7885\n",
      "\n",
      "=================\" 1000 iterations \"=================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      3923\n",
      "           1       0.90      0.93      0.91      3962\n",
      "\n",
      "    accuracy                           0.91      7885\n",
      "   macro avg       0.91      0.91      0.91      7885\n",
      "weighted avg       0.91      0.91      0.91      7885\n",
      "\n",
      "=================\" 3000 iterations \"=================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      3923\n",
      "           1       0.89      0.93      0.91      3962\n",
      "\n",
      "    accuracy                           0.90      7885\n",
      "   macro avg       0.90      0.90      0.90      7885\n",
      "weighted avg       0.90      0.90      0.90      7885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num in num_of_iterations:\n",
    "    model = LogisticRegression(num_iterations=num)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(('\" '+ str(num) +' iterations \"').center(53, '='))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.3, 0.5, 0.65, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\" Threshold = 0.3 \"=================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.21      0.34      3923\n",
      "           1       0.56      0.99      0.71      3962\n",
      "\n",
      "    accuracy                           0.60      7885\n",
      "   macro avg       0.76      0.60      0.53      7885\n",
      "weighted avg       0.76      0.60      0.53      7885\n",
      "\n",
      "=================\" Threshold = 0.5 \"=================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.81      3923\n",
      "           1       0.99      0.55      0.71      3962\n",
      "\n",
      "    accuracy                           0.77      7885\n",
      "   macro avg       0.84      0.77      0.76      7885\n",
      "weighted avg       0.84      0.77      0.76      7885\n",
      "\n",
      "=================\" Threshold = 0.65 \"================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89      3923\n",
      "           1       0.86      0.95      0.90      3962\n",
      "\n",
      "    accuracy                           0.90      7885\n",
      "   macro avg       0.90      0.90      0.90      7885\n",
      "weighted avg       0.90      0.90      0.90      7885\n",
      "\n",
      "=================\" Threshold = 0.8 \"=================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      3923\n",
      "           1       0.90      0.92      0.91      3962\n",
      "\n",
      "    accuracy                           0.91      7885\n",
      "   macro avg       0.91      0.91      0.91      7885\n",
      "weighted avg       0.91      0.91      0.91      7885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thresh in threshold:\n",
    "    model = LogisticRegression(threshold=thresh)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(('\" Threshold = '+ str(thresh) +' \"').center(53, '='))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
