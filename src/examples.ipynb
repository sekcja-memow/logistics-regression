{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "#### HERE ARE SOME EXAMPLES AND TESTS ####\n",
    "##########################################\n",
    "\n",
    "\n",
    "from core.models import *\n",
    "from core.optimizers import *\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import classification_report\n",
    "import pip\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to get some data for training and testing our model\n",
    "# iris is basic, well known dataset, we can use it \n",
    "\n",
    "iris = load_iris()       # loading whole dataset\n",
    "X = iris.data[:,:2]               # we can cut data, we don't need the whole dataset\n",
    "y = (iris.target != 0) * 1        # read target values, they have to be binary, so we do class 1 from class 2 \n",
    "\n",
    "\n",
    "# now the train-test split\n",
    "X_train, X_test, y_train, y_test = tts(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<core.models.LogisticRegression at 0x27fa26663c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = RMSPropOptimizer(learning_rate=0.03)\n",
    "\n",
    "model = LogisticRegression(optimizer=optimizer, num_iterations=200, fit_intercept=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.DataFrame(X_test)\n",
    "# df['y'] = y_test\n",
    "# df['pred'] = model.predict(X_test)\n",
    "\n",
    "# a, b = model.theta[0], model.theta[1]\n",
    "# foo = lambda x: a * x + b\n",
    "\n",
    "# sns.scatterplot(data=df, x=0, y=1, hue='pred')\n",
    "# plt.plot([4, 8], [foo(4), foo(8)])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def remove_correlated_features(X):\n",
    "    corr_threshold = 0.9\n",
    "    corr = X.corr()\n",
    "    drop_columns = np.full(corr.shape[0], False, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i + 1, corr.shape[0]):\n",
    "            if corr.iloc[i, j] >= corr_threshold:\n",
    "                drop_columns[j] = True\n",
    "    columns_dropped = X.columns[drop_columns]\n",
    "    X.drop(columns_dropped, axis=1, inplace=True)\n",
    "    return columns_dropped\n",
    "\n",
    "\n",
    "def remove_less_significant_features(X, Y):\n",
    "    sl = 0.05\n",
    "    regression_ols = None\n",
    "    columns_dropped = np.array([])\n",
    "    for itr in range(0, len(X.columns)):\n",
    "        regression_ols = sm.OLS(Y, X).fit()\n",
    "        max_col = regression_ols.pvalues.idxmax()\n",
    "        max_val = regression_ols.pvalues.max()\n",
    "        if max_val > sl:\n",
    "            X.drop(max_col, axis='columns', inplace=True)\n",
    "            columns_dropped = np.append(columns_dropped, [max_col])\n",
    "        else:\n",
    "            break\n",
    "    regression_ols.summary()\n",
    "    return columns_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading dataset...\n",
      "applying feature engineering...\n",
      "splitting dataset into train and test sets...\n",
      "training started...\n",
      "Epoch is: 1 and Cost is: 7097.942267072146\n",
      "Epoch is: 2 and Cost is: 6448.434998545462\n",
      "Epoch is: 4 and Cost is: 5390.669680472762\n",
      "Epoch is: 8 and Cost is: 3842.295840012008\n",
      "Epoch is: 16 and Cost is: 2704.12416434212\n",
      "Epoch is: 32 and Cost is: 1947.0545098690081\n",
      "Epoch is: 64 and Cost is: 1529.1760504792114\n",
      "Epoch is: 128 and Cost is: 1278.5002229709903\n",
      "Epoch is: 256 and Cost is: 1141.0804777565406\n",
      "Epoch is: 512 and Cost is: 1053.6175599556097\n",
      "Epoch is: 1023 and Cost is: 1008.4292013948714\n",
      "training finished.\n",
      "testing the model...\n"
     ]
    }
   ],
   "source": [
    "print(\"reading dataset...\")\n",
    "# read data in pandas (pd) data frame\n",
    "data = pd.read_csv('./datasets/breast_cancer.csv')\n",
    "\n",
    "# drop last column (extra column added by pd)\n",
    "# and unnecessary first column (id)\n",
    "data.drop(data.columns[[-1, 0]], axis=1, inplace=True)\n",
    "\n",
    "print(\"applying feature engineering...\")\n",
    "# convert categorical labels to numbers\n",
    "diag_map = {'M': 1.0, 'B': -1.0}\n",
    "data['diagnosis'] = data['diagnosis'].map(diag_map)\n",
    "\n",
    "# put features & outputs in different data frames\n",
    "Y = data.loc[:, 'diagnosis']\n",
    "X = data.iloc[:, 1:]\n",
    "\n",
    "# filter features\n",
    "remove_correlated_features(X)\n",
    "remove_less_significant_features(X, Y)\n",
    "\n",
    "# normalize data for better convergence and to prevent overflow\n",
    "X_normalized = MinMaxScaler().fit_transform(X.values)\n",
    "X = pd.DataFrame(X_normalized)\n",
    "\n",
    "# split data into train and test set\n",
    "print(\"splitting dataset into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = tts(\n",
    "    X, Y, test_size=0.2)\n",
    "\n",
    "# train the model\n",
    "print(\"training started...\")\n",
    "classifier = SVM()\n",
    "classifier.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "print(\"training finished.\")\n",
    "\n",
    "# testing the model\n",
    "print(\"testing the model...\")\n",
    "# coś tu sie sypie, jutro zerknę o co chodzi, coś z wymiarami\n",
    "# y_pr = classifier.predict(X_test)\n",
    "# classifier.evaluate(y_test, y_pr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
